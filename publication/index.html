<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.8.0"><meta name=author content="Web Administrator"><meta name=description content="Datability is all about the ability to use large volumes of data sustainably and responsibly."><link rel=alternate hreflang=ja href=http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/ja/publication/><link rel=alternate hreflang=en-us href=http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/><meta name=theme-color content="#2962ff"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/css/academic.css><link rel=alternate href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/index.xml type=application/rss+xml title="Institute for Datability Science, Osaka University"><link rel=manifest href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/index.webmanifest><link rel=icon type=image/png href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png><link rel=canonical href=http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Institute for Datability Science, Osaka University"><meta property="og:url" content="http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/"><meta property="og:title" content="Publications | Institute for Datability Science, Osaka University"><meta property="og:description" content="Datability is all about the ability to use large volumes of data sustainably and responsibly."><meta property="og:image" content="http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/media/large.png"><meta property="twitter:image" content="http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/media/large.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2020-04-01T00:00:00+00:00"><title>Publications | Institute for Datability Science, Osaka University</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/><img src=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/images/logo_hu43423524dbd337905d6e12d1b20a6666_22772_0x70_resize_lanczos_2.png alt="Institute for Datability Science, Osaka University"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/><img src=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/images/logo_hu43423524dbd337905d6e12d1b20a6666_22772_0x70_resize_lanczos_2.png alt="Institute for Datability Science, Osaka University"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class="nav-link active" href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/message><span>Message</span></a></li><li class=nav-item><a class=nav-link href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/organization><span>Organization</span></a></li><li class=nav-item><a class=nav-link href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/projects><span>Projects</span></a></li><li class=nav-item><a class="nav-link active" href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication><span>Publiaction</span></a></li><li class=nav-item><a class=nav-link href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/access><span>Access</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class="nav-link js-theme-selector" data-toggle=dropdown aria-haspopup=true><i class="fas fa-palette" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li><li class="nav-item dropdown i18n-dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><i class="fas fa-globe mr-1" aria-hidden=true></i><span class="d-none d-lg-inline">English</span></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>English</span></div><a class=dropdown-item href=http://www.ids.osaka-u.ac.jp/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/ja/publication/><span>日本語</span></a></div></li></ul></div></nav><div class="universal-wrapper pt-3"><h1>Publications</h1></div><div class=universal-wrapper><div class=row><div class=col-lg-12><div class="form-row mb-4"><div class=col-auto><input type=search class=filter-search placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off role=textbox spellcheck=false></div><div class=col-auto><select class="pub-filters pubtype-select form-control form-control-sm" data-filter-group=pubtype>
<option value=*>Type</option>
<option value=.pubtype-1>Conference paper</option>
<option value=.pubtype-2>Journal article</option>
<option value=.pubtype-5>Book</option></select></div><div class=col-auto><select class="pub-filters form-control form-control-sm" data-filter-group=year>
<option value=*>Date</option>
<option value=.year-2020>2020</option>
<option value=.year-2019>2019</option>
<option value=.year-2018>2018</option>
<option value=.year-2017>2017</option>
<option value=.year-2016>2016</option></select></div></div><div id=container-publications><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Manisha Verma</span>, <span>Sudhakar Kumawat</span>, <span>Yuta Nakashima</span>, <span>Shanmuganathan Raman</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/verma-2020/>Yoga-82: a new dataset for fine-grained classification of human poses</a>.
<em>The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://openaccess.thecvf.com/content_CVPRW_2020/papers/w70/Verma_Yoga-82_A_New_Dataset_for_Fine-Grained_Classification_of_Human_Poses_CVPRW_2020_paper.pdf target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/verma-2020/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Kiminori Yanagisawa</span>, <span>Masayasu Toratani</span>, <span>Ayumu Asai</span>, <span>Masamitsu Konno</span>, <span>Hirohiko Niioka</span>, <span>Tsunekazu Mizushima</span>, <span>Taroh Satoh</span>, <span>Jun Miyake</span>, <span>Kazuhiko Ogawa</span>, <span>Andrea Vecchione</span>, <span>Yuichiro Doki</span>, <span>Hidetoshi Eguchi</span>, <span>Hideshi Ishii</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yanagisawa-2020/>Convolutional Neural Network Can Recognize Drug Resistance of Single Cancer Cells</a>.
<em>International Journal of Molecular Sciences</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.mdpi.com/1422-0067/21/9/3166 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yanagisawa-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.3390/ijms21093166 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Shogo Terai</span>, <span>Shizuka Shirai</span>, <span>Mehrasa Alizadeh</span>, <span>Ryosuke Kawamura</span>, <span>Noriko Takemura</span>, <span>Yuki Uranishi</span>, <span>Haruo Takemura</span>, <span>Hajime Nagahara</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/terai-2020/>Detecting learner drowsiness based on facial expressions and head movements in online courses</a>.
<em>International Conference on Intelligent User Interfaces, Proceedings IUI</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/terai-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1145/3379336.3381500 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Noa Garcia</span>, <span>Mayu Otani</span>, <span>Chenhui Chu</span>, <span>Yuta Nakashima</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/garcia-2020-a/>KnowIT VQA: Answering knowledge-based questions about videos</a>.
<em>Proceedings - 2020 AAAI Conference on Artificial Intelligence</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://arxiv.org/abs/1910.10706%20https://aaai.org/ojs/index.php/AAAI/article/view/6713/6567 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/garcia-2020-a/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>T. Kimura</span>, <span>N. Takemura</span>, <span>Y. Nakashima</span>, <span>H. Kobori</span>, <span>H. Nagahara</span>, <span>M. Numao</span>, <span>K. Shinohara</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kimura-2020/>Warmer Environments Increase Implicit Mental Workload Even If Learning Efficiency Is Enhanced</a>.
<em>Frontiers in Psychology</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kimura-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.3389/fpsyg.2020.00568 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Yuta Nakashima</span>, <span>Takaaki Yasui</span>, <span>Leon Nguyen</span>, <span>Noboru Babaguchi</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nakashima-2020/>Speech-driven face reenactment for a video sequence</a>.
<em>ITE Transactions on Media Technology and Applications</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nakashima-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.3169/mta.8.60 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Liangzhi Li</span>, <span>Manisha Verma</span>, <span>Yuta Nakashima</span>, <span>Ryo Kawasaki</span>, <span>Hajime Nagahara</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/li-2020-a/>Joint learning of vessel segmentation and artery/vein classification with post-processing</a>.
<em>Medical Imaging with Deep Learning (MIDL)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.liangzhili.com/publication/li-2020-joint/ target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/li-2020-a/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Liangzhi Li</span>, <span>Manisha Verma</span>, <span>Yuta Nakashima</span>, <span>Hajime Nagahara</span>, <span>Ryo Kawasaki</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/li-2020/>IterNet: retinal image segmentation utilizing structural redundancy in vessel networks</a>.
<em>Proceedings - The IEEE Winter Conference on Applications of Computer Vision (WACV)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.liangzhili.com/publication/li-2020-iternet/ target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/li-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/wacv45572.2020.9093621 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Noa Garcia</span>, <span>Benjamin Renoust</span>, <span>Yuta Nakashima</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/garcia-2020/>ContextNet: representation and exploration for painting classification and retrieval in context</a>.
<em>International Journal of Multimedia Information Retrieval</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/garcia-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/s13735-019-00189-4 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Zekun Yang</span>, <span>Noa Garcia</span>, <span>Chenhui Chu</span>, <span>Mayu Otani</span>, <span>Yuta Nakashima</span>, <span>Haruo Takemura</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yang-2020/>BERT representations for video question answering</a>.
<em>Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yang-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/WACV45572.2020.9093596 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2020"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Takahiro Yamaguchi</span>, <span>Hajime Nagahara</span>, <span>Ken'ichi Morooka</span>, <span>Yuta Nakashima</span>, <span>Yuki Uranishi</span>, <span>Shoko Miyauchi</span>, <span>Ryo Kurazume</span></span>
(2020).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yamaguchi-2020/>3D Image Reconstruction from Multi-focus Microscopic Images</a>.
<em>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yamaguchi-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-030-39770-8_6 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Thanh Trung Ngo</span>, <span>Hajime Nagahara</span>, <span>Ko Nishino</span>, <span>Rin ichiro Taniguchi</span>, <span>Yasushi Yagi</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ngo-2019/>Reflectance and Shape Estimation with a Light Field Camera Under Natural Illumination</a>.
<em>International Journal of Computer Vision</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ngo-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/s11263-019-01149-5 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Tatsuya Matsumoto</span>, <span>Hirohiko Niioka</span>, <span>Yasuaki Kumamoto</span>, <span>Junya Sato</span>, <span>Osamu Inamori</span>, <span>Ryuta Nakao</span>, <span>Yoshinori Harada</span>, <span>Eiichi Konishi</span>, <span>Eigo Otsuji</span>, <span>Hideo Tanaka</span>, <span>Jun Miyake</span>, <span>Tetsuro Takamatsu</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/matsumoto-2019/>Deep-UV excitation fluorescence microscopy for detection of lymph node metastasis using deep neural network</a>.
<em>Scientific Reports</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://www.nature.com/articles/s41598-019-53405-w target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/matsumoto-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1038/s41598-019-53405-w target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Kazuki Ashihara</span>, <span>Tomoyuki Kajiwara</span>, <span>Yuki Arase</span>, <span>Satoru Uchida</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ashihara-2019-a/>Contextualized multi-sense word embedding</a>.
<em>Journal of Natural Language Processing</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.jstage.jst.go.jp/article/jnlp/26/4/26_689/_article/-char/ja/ target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ashihara-2019-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.5715/jnlp.26.689 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Kazuki Ashihara</span>, <span>Chenhui Chu</span>, <span>Benjamin Renoust</span>, <span>Noriko Okubo</span>, <span>Noriko Takemura</span>, <span>Yuta Nakashima</span>, <span>Hajime Nagahara</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ashihara-2019-b/>Legal information as a complex network: Improving topic modeling through homophily</a>.
<em>Proceedings - International Conference on Complex Networks and Their Applications</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ashihara-2019-b/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-030-36683-4_3 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Akihiko Sayo</span>, <span>Hayato Onizuka</span>, <span>Diego Thomas</span>, <span>Yuta Nakashima</span>, <span>Hiroshi Kawasaki</span>, <span>Katsushi Ikeuchi</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/sayo-2019/>Human shape reconstruction with loose clothes from partially observed data by pose specific deformation</a>.
<em>Proceedings - Pacific-Rim Symposium on Image and Video Technology</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/sayo-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-030-34879-3_18 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Thuong Nguyen Canh</span>, <span>Hajime Nagahara</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nguyen-canh-2019/>Deep compressive sensing for visual privacy protection in flatcam imaging</a>.
<em>Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nguyen-canh-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICCVW.2019.00492 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Hiroki Shimanaka</span>, <span>Tomoyuki Kajiwara</span>, <span>Mamoru Komachi</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shimanaka-2019/>Metric for automatic machine translation evaluation based on pre-trained sentence embeddings</a>.
<em>Journal of Natural Language Processing</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.jstage.jst.go.jp/article/jnlp/26/3/26_613/_article/-char/ja/ target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shimanaka-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.5715/jnlp.26.613 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Keita Maruyama</span>, <span>Yasutaka Inagaki</span>, <span>Keita Takahashi</span>, <span>Toshiaki Fujii</span>, <span>Hajime Nagahara</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/maruyama-2019/>A 3-D Display Pipeline from Coded-Aperture Camera to Tensor Light-Field Display Through CNN</a>.
<em>Proceedings - International Conference on Image Processing, ICIP</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/maruyama-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICIP.2019.8803741 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Masahito Yamanaka</span>, <span>Hirohiko Niioka</span>, <span>Taichi Furukawa</span>, <span>Norihiko Nishizawa</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yamanaka-2019/>Excitation of erbium-doped nanoparticles in 1550-nm wavelength region for deep tissue imaging with reduced degradation of spatial resolution</a>.
<em>Journal of Biomedical Optics</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-24/issue-07/070501/Excitation-of-erbium-doped-nanoparticles-in-1550-nm-wavelength-region/10.1117/1.JBO.24.7.070501.full target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yamanaka-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1117/1.JBO.24.7.070501 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Masahiro Yanagawa</span>, <span>Hirohiko Niioka</span>, <span>Akinori Hata</span>, <span>Noriko Kikuchi</span>, <span>Osamu Honda</span>, <span>Hiroyuki Kurakami</span>, <span>Eiichi Morii</span>, <span>Masayuki Noguchi</span>, <span>Yoshiyuki Watanabe</span>, <span>Jun Miyake</span>, <span>Noriyuki Tomiyama</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yanagawa-2019/>Application of deep learning (3-dimensional convolutional neural network) for the prediction of pathological invasiveness in lung adenocarcinoma</a>.
<em>Medicine</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://journals.lww.com/00005792-201906210-00044 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yanagawa-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1097/MD.0000000000016119 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Shizuka Shirai</span>, <span>Noriko Takemura</span>, <span>Yuta Nakashima</span>, <span>Hajime Nagahara</span>, <span>Haruo Takemura</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shirai-2019/>Multimodal learning analytics: Society 5.0 project in Japan</a>.
<em>Companion Proceedings of the 9th International Conference on Learning Analytics & Knowledge</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shirai-2019/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Chao Ma</span>, <span>Atsushi Shimada</span>, <span>Hideaki Uchiyama</span>, <span>Hajime Nagahara</span>, <span>Rin ichiro Taniguchi</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ma-2019/>Fall detection using optical level anonymous image sensing system</a>.
<em>Optics and Laser Technology</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ma-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1016/j.optlastec.2018.07.013 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Noa Garcia</span>, <span>Chenhui Chu</span>, <span>Mayu Otani</span>, <span>Yuta Nakashima</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/noa-garcia-chenhui-chu-2019/>Video meets knowledge in visual question answering</a>.
<em>画像の認識・理解シンポジウム(MIRU2019)論文集</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/noa-garcia-chenhui-chu-2019/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Mayu Otani</span>, <span>Yuta Nakashima</span>, <span>Esa Rahtu</span>, <span>Janne Heikkilä</span>, <span>Janne Heikkila</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2019-a/>Rethinking the evaluation of video summaries</a>.
<em>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2019-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/CVPR.2019.00778 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Tomoyuki Kajiwara</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kajiwara-2020/>Negative lexically constrained decoding for paraphrase generation</a>.
<em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.aclweb.org/anthology/P19-1607/ target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kajiwara-2020/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/P19-1607 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>B. Renoust</span>, <span>M.O. Franca</span>, <span>J. Chan</span>, <span>N. Garcia</span>, <span>V. Le</span>, <span>A. Uesaka</span>, <span>Y. Nakashima</span>, <span>H. Nagahara</span>, <span>J. Wang</span>, <span>Y. Fujioka</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/renoust-2019/>Historical and modern features for Buddha statue classification</a>.
<em>SUMAC 2019 - Proceedings of the 1st Workshop on Structuring and Understanding of Multimedia heritAge Contents, co-located with MM 2019</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/renoust-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1145/3347317.3357239 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Manisha Verma</span>, <span>Hirokazu Kobori</span>, <span>Yuta Nakashima</span>, <span>Noriko Takemura</span>, <span>Hajime Nagahara</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/verma-2019/>Facial expression recognition with skip-connection to leverage low-level features</a>.
<em>Proceedings - IEEE International Conference on Image Processing (ICIP)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://ieeexplore.ieee.org/abstract/document/8803396 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/verma-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICIP.2019.8803396 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>R. Tsutsumi</span>, <span>T. Ikeda</span>, <span>H. Nagahara</span>, <span>H. Saeki</span>, <span>Y. Nakashima</span>, <span>E. Oki</span>, <span>Y. Maehara</span>, <span>M. Hashizume</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/tsutsumi-2019/>Efficacy of Novel Multispectral Imaging Device to Determine Anastomosis for Esophagogastrostomy</a>.
<em>Journal of Surgical Research</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/tsutsumi-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1016/j.jss.2019.04.033 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Daiki. Nishihara</span>, <span>Tomoyuki. Kajiwara</span>, <span>Yuki. Arase</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nishihara-2019/>Controllable text simplification with lexical constraint loss</a>.
<em>Proceedings of the ACL 2019 Student Research Workshop (ACL 2019 SRW)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.aclweb.org/anthology/P19-2036/ target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nishihara-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/P19-2036 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Kazuki Ashihara</span>, <span>Tomoyuki Kajiwara</span>, <span>Yuki Arase</span>, <span>Satoru Uchida</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ashihara-2019/>Contextualized context2vec</a>.
<em>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.aclweb.org/anthology/D19-5552 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ashihara-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/D19-5552 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Noa Garcia</span>, <span>Benjamin Renoust</span>, <span>Yuta Nakashima</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/garcia-2019-a/>Context-aware embeddings for automatic art analysis</a>.
<em>Proceedings of the 2019 ACM International Conference on Multimedia Retrieval (ICMR)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/garcia-2019-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1145/3323873.3325028 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Benjamin Renoust</span>, <span>Matheus Oliveira M.O. Franca</span>, <span>Jacob Chan</span>, <span>Van Le</span>, <span>Ayaka Uesaka</span>, <span>Yuta Nakashima</span>, <span>Hajime Nagahara</span>, <span>Jueren Wang</span>, <span>Yutaka Fujioka</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/renoust-2019-a/>Buda.art: A multimodal content-based analysis and retrieval system for Buddha statues</a>.
<em>Proceedings of the 27th ACM International Conference on Multimedia (MM)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/renoust-2019-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1145/3343031.3350591 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-5 year-2019"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>H. Hamasaki</span>, <span>S. Takeshita</span>, <span>K. Nakai</span>, <span>T. Sonoda</span>, <span>H. Kawasaki</span>, <span>H. Nagahara</span>, <span>S. Ono</span></span>
(2019).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/hamasaki-2019/>A Coded Aperture for Watermark Extraction from Defocused Images</a>.
<em>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/hamasaki-2019/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-030-20876-9_15 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Hajime Nagahara</span>, <span>Dengyu Liu</span>, <span>Toshiki Sonoda</span>, <span>Jinwei Gu</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nagahara-2018/>Space-time-brightness sampling using an adaptive pixel-wise coded exposure</a>.
<em>IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nagahara-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/CVPRW.2018.00237 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Ryosuke Kimura</span>, <span>Akihiko Sayo</span>, <span>Fabian Lorenzo Dayrit</span>, <span>Yuta Nakashima</span>, <span>Hiroshi Kawasaki</span>, <span>Ambrosio Blanco</span>, <span>Katsushi Ikeuchi</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kimura-2018/>Representing a partially observed non-rigid 3D human using eigen-texture and eigen-deformation</a>.
<em>Proceedings - International Conference on Pattern Recognition (ICPR)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kimura-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICPR.2018.8545658 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Mayu Otani</span>, <span>Atsushi Nishida</span>, <span>Yuta Nakashima</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2018/>Finding important people in a video using deep neural networks with conditional random fields</a>.
<em>IEICE Transactions on Information and Systems</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1587/transinf.2018EDP7029 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Keigo Hirose</span>, <span>Shuichiro Fukushima</span>, <span>Taichi Furukawa</span>, <span>Hirohiko Niioka</span>, <span>Mamoru Hashimoto</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/hirose-2018/>Invited Article: Label-free nerve imaging with a coherent anti-Stokes Raman scattering rigid endoscope using two optical fibers for laser delivery</a>.
<em>APL Photonics</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://aip.scitation.org/doi/10.1063/1.5031817 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/hirose-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1063/1.5031817 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Yusuke Yagi</span>, <span>Keita Takahashi</span>, <span>Toshiaki Fujii</span>, <span>Toshiki Sonoda</span>, <span>Hajime Nagahara</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yagi-2018/>Designing coded aperture camera based on PCA and NMF for light field acquisition</a>.
<em>IEICE Transactions on Information and Systems</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yagi-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1587/transinf.2017PCP0007 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Antonio Tejero-De-Pablos</span>, <span>Yuta Nakashima</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span>, <span>Marko Linna</span>, <span>Esa Rahtu</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/tejero-de-pablos-2018/>Summarization of user-generated sports video by using deep action recognition features</a>.
<em>IEEE Transactions on Multimedia</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://ieeexplore.ieee.org/document/8259321 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/tejero-de-pablos-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/TMM.2018.2794265 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Takahiro Tanaka</span>, <span>Norihiko Kawai</span>, <span>Yuta Nakashima</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/tanaka-2018/>Iterative applications of image completion with CNN-based failure detection</a>.
<em>Journal of Visual Communication and Image Representation</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/tanaka-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1016/j.jvcir.2018.05.015 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Chenhui Chu</span>, <span>Mayu Otani</span>, <span>Yuta Nakashima</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/chu-2018-a/>iParaphrasing: Extracting visually grounded paraphrases via an image</a>.
<em>Proceedings - International Conference on Compuational Linguistics (COLING)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://arxiv.org/abs/1806.04284 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/chu-2018-a/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Yusuke Yagi</span>, <span>Keita Takahashi</span>, <span>Toshiaki Fujii</span>, <span>Toshiki Sonoda</span>, <span>Hajime Nagahara</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yagi-2018-a/>PCA-coded aperture for light field photography</a>.
<em>Proceedings - International Conference on Image Processing, ICIP</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yagi-2018-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICIP.2017.8296839 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Chenhui Chu</span>, <span>Mayu Otani</span>, <span>Yuta Nakashima</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/chu-2018/>Visually grounded paraphrase extraction</a>.
<em>Proceedings of the 27th International Conference on Computational Linguistics</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/chu-2018/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>T. Yoda</span>, <span>H. Nagahara</span>, <span>R.-I. Taniguchi</span>, <span>K. Kagawa</span>, <span>K. Yasutomi</span>, <span>S. Kawahito</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yoda-2018/>The dynamic photometric stereo method using a multi-tap CMOS image sensor</a>.
<em>Sensors (Switzerland)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yoda-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.3390/s18030786 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Hiroki Shimanaka</span>, <span>Tomoyuki Kajiwara</span>, <span>Mamoru Komachi</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shimanaka-2018/>RUSE: Regressor using sentence embeddings for automatic machine translation evaluation</a>.
<em>Proceedings of the Third Conference on Machine Translation: Shared Task Papers (WMT 18)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://aclweb.org/anthology/W18-6456 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shimanaka-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/W18-6456 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Hiroki Shimanaka</span>, <span>Tomoyuki Kajiwara</span>, <span>Mamoru Komachi</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shimanaka-2018-a/>Metric for automatic machine translation evaluation based on universal sentence representations</a>.
<em>Proceedings of the NAACL 2018 Student Research Workshop (NAACL 2018 SRW)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://aclweb.org/anthology/N18-4015 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/shimanaka-2018-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/N18-4015 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Yasutaka Inagaki</span>, <span>Yuto Kobayashi</span>, <span>Keita Takahashi</span>, <span>Toshiaki Fujii</span>, <span>Hajime Nagahara</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/inagaki-2018/>Learning to capture light fields through a coded aperture camera</a>.
<em>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/inagaki-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-030-01234-2_26 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Michitaka Yoshida</span>, <span>Akihiko Torii</span>, <span>Masatoshi Okutomi</span>, <span>Kenta Endo</span>, <span>Yukinobu Sugiyama</span>, <span>Rin Ichiro Taniguchi</span>, <span>Hajime Nagahara</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yoshida-2018/>Joint optimization for compressive video sensing and reconstruction under hardware constraints</a>.
<em>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yoshida-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-030-01249-6_39 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>J. Miyake</span>, <span>Y. Kaneshita</span>, <span>S. Asatani</span>, <span>S. Tagawa</span>, <span>H. Niioka</span>, <span>T. Hirano</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/miyake-2018/>Graphical classification of DNA sequences of HLA alleles by deep learning</a>.
<em>Human Cell</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/miyake-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/s13577-017-0194-6 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Tomoyuki Kajiwara</span>, <span>Mamoru Komachi</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kajiwara-2018/>Complex word identification based on frequency in a learner corpus</a>.
<em>Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications (BEA 13)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://aclweb.org/anthology/W18-0521 target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kajiwara-2018/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/W18-0521 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2018"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>K. Hirose</span>, <span>T. Aoki</span>, <span>T. Furukawa</span>, <span>S. Fukushima</span>, <span>H. Niioka</span>, <span>S. Deguchi</span>, <span>M. Hashimoto</span></span>
(2018).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/hirose-2018-a/>Coherent anti-stokes Raman scattering rigid endoscope toward robot-assisted surgery</a>.
<em>Biomedical Optics Express</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/hirose-2018-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1364/BOE.9.000387 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Chao Ma</span>, <span>Ngo Thanh Trung</span>, <span>Hideaki Uchiyama</span>, <span>Hajime Nagahara</span>, <span>Atsushi Shimada</span>, <span>Rin Ichiro Taniguchi</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ma-2017-a/>Adapting local features for face detection in thermal image</a>.
<em>Sensors (Switzerland)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ma-2017-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.3390/s17122741 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Norihiko Kawai</span>, <span>Tomokazu Sato</span>, <span>Yuta Nakashima</span>, <span>Naokazu Yokoya</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kawai-2017-a/>Augmented reality marker hiding with texture deformation</a>.
<em>IEEE Transactions on Visualization and Computer Graphics</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/kawai-2017-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/TVCG.2016.2617325 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Tsubasa Minematsu</span>, <span>Hideaki Uchiyama</span>, <span>Atsushi Shimada</span>, <span>Hajime Nagahara</span>, <span>Rin ichiro Taniguchi</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/minematsu-2017/>Adaptive background model registration for moving cameras</a>.
<em>Pattern Recognition Letters</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/minematsu-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1016/j.patrec.2017.03.010 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Thiwat Rongsirigul</span>, <span>Yuta Nakashima</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/rongsirigul-2017/>Novel view synthesis with light-weight view-dependent texture mapping for a stereoscopic HMD</a>.
<em>Proceedings - IEEE International Conference on Multimedia and Expo</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/rongsirigul-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICME.2017.8019417 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Mayu Otani</span>, <span>Yuta Nakashima</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017-c/>Video summarization using textual descriptions for authoring video blogs</a>.
<em>Multimedia Tools and Applications</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017-c/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/s11042-016-4061-3 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Makoto Ohsaki</span>, <span>Hajime Nagahara</span>, <span>Tetsuo Ikeda</span>, <span>Rin-ichiro Taniguchi</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ohsaki-2017/>Hyperspectral imaging using flickerless active LED illumination</a>.
<em>Thirteenth International Conference on Quality Control by Artificial Vision 2017</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ohsaki-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1117/12.2266765 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Mayu Otani</span>, <span>Yuta Nakashima</span>, <span>Esa Rahtu</span>, <span>Janne Heikkilä</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017-b/>Video question answering to find a desired video eegment</a>.
<em>Proceedings - Open Knowledge Base and Question Answering Workshop at SIGIR</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017-b/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Mayu Otani</span>, <span>Yuta Nakashima</span>, <span>Esa Rahtu</span>, <span>Janne Heikkilä</span>, <span>Naokazu Yokoya</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017-a/>Unsupervised Video Summarization using Deep Video Features</a>.
<em>画像の認識・理解シンポジウム(MIRU2017)論文集</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017-a/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Fabian Lorenzo Dayrit</span>, <span>Ryosuke Kimura</span>, <span>Yuta Nakashima</span>, <span>Ambrosio Blanco</span>, <span>Hiroshi Kawasaki</span>, <span>Katsushi Ikeuchi</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/dayrit-2017/>ReMagicMirror: Action learning using human reenactment with the mirror metaphor</a>.
<em>Proceedings - International Conference on Multimedia Modeling (MMM)</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/dayrit-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-319-51811-4_25 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Yuta Nakashima</span>, <span>Fumio Okura</span>, <span>Norihiko Kawai</span>, <span>Hiroshi Kawasaki</span>, <span>Ambrosio Blanco</span>, <span>Katsushi Ikeuchi</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nakashima-2017/>Realtime novel view synthesis with eigen-texture regression</a>.
<em>Proceedings - British Machine Vision Conference (BMVC)</em>.<p><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=http://www.bmva.org/bmvc/2017/papers/paper083/paper083.pdf target=_blank rel=noopener>PDF</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nakashima-2017/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>C. Ma</span>, <span>N.T. Trung</span>, <span>H. Uchiyama</span>, <span>H. Nagahara</span>, <span>A. Shimada</span>, <span>R.-I. Taniguchi</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ma-2017/>Mixed features for face detection in thermal image</a>.
<em>Proceedings of SPIE - The International Society for Optical Engineering</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/ma-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1117/12.2266836 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>R. Roberto</span>, <span>H. Uchiyama</span>, <span>J.P. Lima</span>, <span>H. Nagahara</span>, <span>R.-I. Taniguchi</span>, <span>V. Teichrieb</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/roberto-2017/>Incremental structural modeling on sparse visual SLAM</a>.
<em>Proceedings of the 15th IAPR International Conference on Machine Vision Applications, MVA 2017</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/roberto-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.23919/MVA.2017.7986765 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Fabian Lorenzo Dayrit</span>, <span>Yuta Nakashima</span>, <span>Tomokazu Sato</span>, <span>Naokazu Yokoya</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/dayrit-2017-a/>Increasing pose comprehension through augmented reality reenactment</a>.
<em>Multimedia Tools and Applications</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/dayrit-2017-a/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/s11042-015-3116-1 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Mayu Otani</span>, <span>Yuta Nakashima</span>, <span>Esa Rahtu</span>, <span>Janne Heikkilä</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017/>Fine-grained video retrieval for multi-clip video</a>.
<em>Proceeedings - Workshop on Closing the Loop Between Vision and Language at ICCV</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/otani-2017/cite.bib>
Cite</button></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>H. Niioka</span>, <span>S. Asatani</span>, <span>A. Yoshimura</span>, <span>H. Ohigashi</span>, <span>S. Tagawa</span>, <span>J. Miyake</span></span>
(2017).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/niioka-2017/>Classification of C2C12 cells at differentiation by convolutional neural network of deep learning using phase contrast images</a>.
<em>Human Cell</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/niioka-2017/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/s13577-017-0191-9 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2016"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Hajime Nagahara</span>, <span>Toshiki Sonoda</span>, <span>Kenta Endo</span>, <span>Yukinobu Sugiyama</span>, <span>Rin Ichiro Taniguchi</span></span>
(2016).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nagahara-2016/>High-speed imaging using CMOS image sensor with quasi pixel-wise exposure</a>.
<em>2016 IEEE International Conference on Computational Photography, ICCP 2016 - Proceedings</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/nagahara-2016/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICCPHOT.2016.7492875 target=_blank rel=noopener>DOI</a></p></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2016"><div class=pub-list-item style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i><span class="article-metadata li-cite-author"><span>Takuya Yoda</span>, <span>Hajime Nagahara</span>, <span>Rin Ichiro Taniguchi</span>, <span>Keiichiro Kagawa</span>, <span>Keita Yasutomi</span>, <span>Shoji Kawahito</span></span>
(2016).
<a href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yoda-2016/>Dynamic photometric stereo method using multi-tap CMOS image sensor</a>.
<em>Proceedings - International Conference on Pattern Recognition</em>.<p><button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/publication/yoda-2016/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1109/ICPR.2016.7899988 target=_blank rel=noopener>DOI</a></p></div></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin=anonymous></script><script>const code_highlighting=true;</script><script>const isSiteThemeDark=false;</script><script>const search_config={"indexURI":"/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/index.json","minLength":1,"threshold":0.3};const i18n={"no_results":"No results found","placeholder":"Search...","results":"results found"};const content_type={'post':"Posts",'project':"Projects",'publication':"Publications",'talk':"Talks",'slides':"Slides"};</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/js/academic.min.66c553246b0f279a03be6e5597f72b52.js></script><div class=container><footer class=site-footer><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/><img src=/test/preview/e17f2badfaa26f05e6d577b35eeb867a434bd466/images/logo_hu43423524dbd337905d6e12d1b20a6666_22772_0x70_resize_lanczos_2.png alt="Institute for Datability Science, Osaka University"></a></div><p class=powered-by style=font-size:70%;text-align:left;margin-left:40px>TEL: +81 6 6105 6074<br>FAX: +81 6 6105 6075<br>Techno-alliance bldg. C503, 2-8, Yamadaoka, Suita, Osaka 565-0971</p><p class=powered-by></p><p class=powered-by>Published with
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic Website Builder</a>
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>