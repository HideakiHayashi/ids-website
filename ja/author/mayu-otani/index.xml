<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Mayu Otani | 大阪大学データビリティフロンティア機構</title><link>/ja/author/mayu-otani/</link><atom:link href="/ja/author/mayu-otani/index.xml" rel="self" type="application/rss+xml"/><description>Mayu Otani</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>ja</language><lastBuildDate>Sat, 01 Feb 2020 00:00:00 +0000</lastBuildDate><image><url>/media/large.png</url><title>Mayu Otani</title><link>/ja/author/mayu-otani/</link></image><item><title>KnowIT VQA: Answering knowledge-based questions about videos</title><link>/ja/publication/garcia-2020-a/</link><pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate><guid>/ja/publication/garcia-2020-a/</guid><description/></item><item><title>BERT representations for video question answering</title><link>/ja/publication/yang-2020/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>/ja/publication/yang-2020/</guid><description/></item><item><title>Rethinking the evaluation of video summaries</title><link>/ja/publication/otani-2019-a/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>/ja/publication/otani-2019-a/</guid><description/></item><item><title>Video meets knowledge in visual question answering</title><link>/ja/publication/noa-garcia-chenhui-chu-2019/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>/ja/publication/noa-garcia-chenhui-chu-2019/</guid><description/></item><item><title>Finding important people in a video using deep neural networks with conditional random fields</title><link>/ja/publication/otani-2018/</link><pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate><guid>/ja/publication/otani-2018/</guid><description/></item><item><title>iParaphrasing: Extracting visually grounded paraphrases via an image</title><link>/ja/publication/chu-2018-a/</link><pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate><guid>/ja/publication/chu-2018-a/</guid><description/></item><item><title>Visually grounded paraphrase extraction</title><link>/ja/publication/chu-2018/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>/ja/publication/chu-2018/</guid><description/></item><item><title>Video summarization using textual descriptions for authoring video blogs</title><link>/ja/publication/otani-2017-c/</link><pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate><guid>/ja/publication/otani-2017-c/</guid><description/></item><item><title>Fine-grained video retrieval for multi-clip video</title><link>/ja/publication/otani-2017/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>/ja/publication/otani-2017/</guid><description/></item><item><title>Unsupervised Video Summarization using Deep Video Features</title><link>/ja/publication/otani-2017-a/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>/ja/publication/otani-2017-a/</guid><description/></item><item><title>Video question answering to find a desired video eegment</title><link>/ja/publication/otani-2017-b/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>/ja/publication/otani-2017-b/</guid><description/></item></channel></rss>